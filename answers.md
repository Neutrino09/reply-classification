Compare results and explain which model you’d use in production and why.
The baseline TF-IDF with Logistic Regression achieved very high performance with an accuracy and macro F1 score of around 0.99, training in under a minute and producing a lightweight model that is fast and easy to deploy. In contrast, the fine-tuned DistilBERT model is significantly larger, slower to train and serve, and requires more computational resources, though it offers advantages in handling more complex, noisy, or varied language. Since both models performed nearly the same on this clean dataset, Logistic Regression is the preferred choice for production due to its efficiency, simplicity, and reliability, while a transformer would only be justified if the application needed to handle much more diverse or ambiguous text inputs.

If you only had 200 labeled replies, how would you improve the model without collecting thousands more?
If only 200 labeled replies were available, I would improve the model by leveraging transfer learning with a pre-trained transformer like DistilBERT, which already encodes rich language knowledge and can adapt with minimal fine-tuning. In addition, I would apply semi-supervised approaches such as self-training or weak supervision, where the model generates pseudo-labels for unlabeled data to expand the training set. Data augmentation techniques like back-translation, paraphrasing, or synonym replacement could also increase data diversity and reduce overfitting without requiring new manual labels.


How would you ensure your reply classifier doesn’t produce biased or unsafe outputs in production?
To ensure the reply classifier does not produce biased or unsafe outputs in production, I would start by carefully curating and balancing the training data so that no reply type is underrepresented, reducing the risk of skewed predictions. I would also implement monitoring and logging of predictions in production to detect systematic errors, bias against certain groups, or drift in model behavior. In addition, I would set up guardrails such as confidence thresholds, fallback rules, and human-in-the-loop review for low-confidence or sensitive cases to ensure that incorrect or unsafe outputs do not reach end users unchecked.



Suppose you want to generate personalized cold email openers using an LLM. What prompt design strategies would you use to keep outputs relevant and non-generic?
To generate personalized cold email openers with an LLM, I would design prompts that include structured context such as the prospect’s name, company, role, and a specific reference (e.g., recent news, product launch, or shared interest). I would also constrain the prompt with clear instructions on tone (professional, concise) and length (1–2 sentences) to avoid overly generic or verbose outputs. Finally, I would use few-shot examples in the prompt to show the model the style and specificity expected, ensuring outputs remain relevant, tailored, and consistent across different prospects.
